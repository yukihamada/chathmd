#!/usr/bin/env python3
"""
Wisbeeè©³ç´°ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆã‚Šç´°ã‹ãè©³ç´°ãªã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã€
å„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«é©åˆ‡ãªé‡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’æŒ¯ã‚Šåˆ†ã‘ã¾ã™ã€‚
"""

import json
import os
import re
from collections import defaultdict
import hashlib
from typing import List, Dict, Any

class DetailedCategoryClassifier:
    def __init__(self):
        self.category_definitions = self._define_categories()
    
    def _define_categories(self) -> Dict[str, Dict]:
        """è©³ç´°ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©"""
        return {
            # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»æŠ€è¡“é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'programming_python': {
                'keywords': ['python', 'pandas', 'numpy', 'django', 'flask', 'matplotlib', 'jupyter'],
                'description': 'Pythoné–¢é€£ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
                'priority': 1
            },
            'programming_web': {
                'keywords': ['html', 'css', 'javascript', 'react', 'vue', 'angular', 'node.js', 'typescript'],
                'description': 'Webãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£',
                'priority': 1
            },
            'programming_data': {
                'keywords': ['ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'sql', 'nosql', 'mongodb', 'mysql', 'postgresql', 'ãƒ‡ãƒ¼ã‚¿åˆ†æ'],
                'description': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†æ',
                'priority': 1
            },
            'programming_ai_ml': {
                'keywords': ['æ©Ÿæ¢°å­¦ç¿’', 'ai', 'äººå·¥çŸ¥èƒ½', 'tensorflow', 'pytorch', 'scikit-learn', 'neural network'],
                'description': 'AIãƒ»æ©Ÿæ¢°å­¦ç¿’é–¢é€£',
                'priority': 1
            },
            'programming_general': {
                'keywords': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'ã‚³ãƒ¼ãƒ‰', 'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', 'ãƒ‡ãƒãƒƒã‚°', 'git', 'github'],
                'description': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ä¸€èˆ¬',
                'priority': 2
            },
            
            # ç§‘å­¦ãƒ»å­¦è¡“é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'science_mathematics': {
                'keywords': ['æ•°å­¦', 'å¾®ç©åˆ†', 'ä»£æ•°', 'å¹¾ä½•', 'çµ±è¨ˆ', 'ç¢ºç‡', 'æ–¹ç¨‹å¼', 'é–¢æ•°'],
                'description': 'æ•°å­¦é–¢é€£',
                'priority': 1
            },
            'science_physics': {
                'keywords': ['ç‰©ç†', 'åŠ›å­¦', 'é›»ç£æ°—', 'é‡å­', 'ç›¸å¯¾æ€§ç†è«–', 'ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'æ³¢å‹•'],
                'description': 'ç‰©ç†å­¦é–¢é€£',
                'priority': 1
            },
            'science_chemistry': {
                'keywords': ['åŒ–å­¦', 'åˆ†å­', 'åŸå­', 'åŒ–å­¦åå¿œ', 'æœ‰æ©ŸåŒ–å­¦', 'ç„¡æ©ŸåŒ–å­¦', 'å…ƒç´ '],
                'description': 'åŒ–å­¦é–¢é€£',
                'priority': 1
            },
            'science_biology': {
                'keywords': ['ç”Ÿç‰©', 'dna', 'éºä¼å­', 'ç´°èƒ', 'é€²åŒ–', 'ç”Ÿæ…‹ç³»', 'ç”Ÿç‰©å­¦'],
                'description': 'ç”Ÿç‰©å­¦é–¢é€£',
                'priority': 1
            },
            'science_general': {
                'keywords': ['ç§‘å­¦', 'å®Ÿé¨“', 'ç†è«–', 'ç ”ç©¶', 'è«–æ–‡', 'ä»®èª¬'],
                'description': 'ç§‘å­¦ä¸€èˆ¬',
                'priority': 2
            },
            
            # è¨€èªãƒ»æ–‡å­¦é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'language_japanese': {
                'keywords': ['æ—¥æœ¬èª', 'ã²ã‚‰ãŒãª', 'ã‚«ã‚¿ã‚«ãƒŠ', 'æ¼¢å­—', 'æ•¬èª', 'æ–¹è¨€', 'æ–‡æ³•'],
                'description': 'æ—¥æœ¬èªãƒ»å›½èªé–¢é€£',
                'priority': 1
            },
            'language_english': {
                'keywords': ['english', 'è‹±èª', 'è‹±ä¼šè©±', 'æ–‡æ³•', 'grammar', 'vocabulary', 'toeic'],
                'description': 'è‹±èªé–¢é€£',
                'priority': 1
            },
            'language_literature': {
                'keywords': ['æ–‡å­¦', 'å°èª¬', 'è©©', 'ä¿³å¥', 'çŸ­æ­Œ', 'ä½œå®¶', 'æ–‡èŠ¸'],
                'description': 'æ–‡å­¦é–¢é€£',
                'priority': 1
            },
            'language_writing': {
                'keywords': ['æ–‡ç« ', 'ä½œæ–‡', 'ã‚¨ãƒƒã‚»ã‚¤', 'è«–æ–‡', 'æ–‡ç« åŠ›', 'è¡¨ç¾'],
                'description': 'æ–‡ç« ä½œæˆãƒ»è¡¨ç¾',
                'priority': 1
            },
            
            # ã‚¢ãƒ¼ãƒˆãƒ»ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'art_visual': {
                'keywords': ['çµµç”»', 'ã‚¤ãƒ©ã‚¹ãƒˆ', 'ãƒ‡ã‚¶ã‚¤ãƒ³', 'è‰²å½©', 'æ§‹å›³', 'ç¾è¡“', 'ã‚¢ãƒ¼ãƒˆ'],
                'description': 'è¦–è¦šèŠ¸è¡“é–¢é€£',
                'priority': 1
            },
            'art_music': {
                'keywords': ['éŸ³æ¥½', 'æ¥½å™¨', 'ä½œæ›²', 'æ­Œ', 'ãƒ¡ãƒ­ãƒ‡ã‚£', 'ãƒªã‚ºãƒ ', 'æ¥½è­œ'],
                'description': 'éŸ³æ¥½é–¢é€£',
                'priority': 1
            },
            'art_performance': {
                'keywords': ['æ¼”åŠ‡', 'ãƒ€ãƒ³ã‚¹', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'èˆå°', 'æ¼”æŠ€'],
                'description': 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èŠ¸è¡“',
                'priority': 1
            },
            'art_crafts': {
                'keywords': ['å·¥èŠ¸', 'é™¶èŠ¸', 'å½«åˆ»', 'æ‰‹ä½œã‚Š', 'diy', 'ã‚¯ãƒ©ãƒ•ãƒˆ'],
                'description': 'å·¥èŠ¸ãƒ»æ‰‹ä½œã‚Š',
                'priority': 1
            },
            
            # æ­´å²ãƒ»æ–‡åŒ–é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'history_japanese': {
                'keywords': ['æ—¥æœ¬å²', 'æˆ¦å›½', 'æ±Ÿæˆ¸', 'æ˜æ²»', 'æ˜­å’Œ', 'å¹³æˆ', 'å¤©çš‡', 'å¹•åºœ'],
                'description': 'æ—¥æœ¬å²é–¢é€£',
                'priority': 1
            },
            'history_world': {
                'keywords': ['ä¸–ç•Œå²', 'ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘', 'ã‚¢ãƒ¡ãƒªã‚«', 'ä¸­å›½', 'å¤ä»£', 'ä¸­ä¸–', 'è¿‘ä¸–'],
                'description': 'ä¸–ç•Œå²é–¢é€£',
                'priority': 1
            },
            'culture_traditional': {
                'keywords': ['ä¼çµ±', 'æ–‡åŒ–', 'ç¥­ã‚Š', 'èŒ¶é“', 'è¯é“', 'æ›¸é“', 'æ­¦é“'],
                'description': 'ä¼çµ±æ–‡åŒ–é–¢é€£',
                'priority': 1
            },
            'culture_modern': {
                'keywords': ['ç¾ä»£æ–‡åŒ–', 'ãƒãƒƒãƒ—ã‚«ãƒ«ãƒãƒ£ãƒ¼', 'ã‚¢ãƒ‹ãƒ¡', 'ãƒãƒ³ã‚¬', 'ã‚²ãƒ¼ãƒ '],
                'description': 'ç¾ä»£æ–‡åŒ–é–¢é€£',
                'priority': 1
            },
            
            # ãƒ“ã‚¸ãƒã‚¹ãƒ»çµŒæ¸ˆé–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'business_management': {
                'keywords': ['çµŒå–¶', 'ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ', 'ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—', 'çµ„ç¹”', 'æˆ¦ç•¥'],
                'description': 'çµŒå–¶ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ',
                'priority': 1
            },
            'business_finance': {
                'keywords': ['é‡‘è', 'æŠ•è³‡', 'æ ªå¼', 'çµŒæ¸ˆ', 'ä¼šè¨ˆ', 'è²¡å‹™'],
                'description': 'é‡‘èãƒ»çµŒæ¸ˆé–¢é€£',
                'priority': 1
            },
            'business_marketing': {
                'keywords': ['ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', 'åºƒå‘Š', 'ãƒ–ãƒ©ãƒ³ãƒ‰', 'å®£ä¼', 'è²©å£²'],
                'description': 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°é–¢é€£',
                'priority': 1
            },
            
            # å¥åº·ãƒ»åŒ»ç™‚é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'health_medical': {
                'keywords': ['åŒ»ç™‚', 'ç—…æ°—', 'æ²»ç™‚', 'è–¬', 'åŒ»å¸«', 'çœ‹è­·', 'ç—…é™¢'],
                'description': 'åŒ»ç™‚é–¢é€£',
                'priority': 1
            },
            'health_fitness': {
                'keywords': ['å¥åº·', 'é‹å‹•', 'ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹', 'ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ', 'ç­‹ãƒˆãƒ¬', 'ãƒ¨ã‚¬'],
                'description': 'å¥åº·ãƒ»ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹',
                'priority': 1
            },
            'health_nutrition': {
                'keywords': ['æ „é¤Š', 'é£Ÿäº‹', 'é£Ÿå“', 'ãƒ“ã‚¿ãƒŸãƒ³', 'ã‚«ãƒ­ãƒªãƒ¼', 'é£Ÿã¹ç‰©'],
                'description': 'æ „é¤Šãƒ»é£Ÿäº‹é–¢é€£',
                'priority': 1
            },
            
            # ç”Ÿæ´»ãƒ»è¶£å‘³é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'lifestyle_cooking': {
                'keywords': ['æ–™ç†', 'ãƒ¬ã‚·ãƒ”', 'èª¿ç†', 'é£Ÿæ', 'ã‚°ãƒ«ãƒ¡', 'å‘³'],
                'description': 'æ–™ç†ãƒ»ã‚°ãƒ«ãƒ¡é–¢é€£',
                'priority': 1
            },
            'lifestyle_travel': {
                'keywords': ['æ—…è¡Œ', 'è¦³å…‰', 'æ—…', 'æµ·å¤–', 'å›½å†…', 'ãƒ›ãƒ†ãƒ«', 'äº¤é€š'],
                'description': 'æ—…è¡Œãƒ»è¦³å…‰é–¢é€£',
                'priority': 1
            },
            'lifestyle_hobbies': {
                'keywords': ['è¶£å‘³', 'ã‚¹ãƒãƒ¼ãƒ„', 'ã‚²ãƒ¼ãƒ ', 'èª­æ›¸', 'æ˜ ç”»', 'éŸ³æ¥½é‘‘è³'],
                'description': 'è¶£å‘³ãƒ»å¨¯æ¥½é–¢é€£',
                'priority': 1
            },
            'lifestyle_fashion': {
                'keywords': ['ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³', 'æœ', 'ãŠã—ã‚ƒã‚Œ', 'ã‚¹ã‚¿ã‚¤ãƒ«', 'ãƒ–ãƒ©ãƒ³ãƒ‰'],
                'description': 'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³é–¢é€£',
                'priority': 1
            },
            
            # æ•™è‚²ãƒ»å­¦ç¿’é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'education_elementary': {
                'keywords': ['å°å­¦æ ¡', 'å°å­¦ç”Ÿ', 'åŸºç¤', 'ç®—æ•°', 'å›½èª', 'ã²ã‚‰ãŒãª'],
                'description': 'å°å­¦æ ¡æ•™è‚²é–¢é€£',
                'priority': 1
            },
            'education_secondary': {
                'keywords': ['ä¸­å­¦æ ¡', 'é«˜æ ¡', 'å—é¨“', 'é€²å­¦', 'éƒ¨æ´»', 'é’æ˜¥'],
                'description': 'ä¸­ç­‰æ•™è‚²é–¢é€£',
                'priority': 1
            },
            'education_higher': {
                'keywords': ['å¤§å­¦', 'å¤§å­¦é™¢', 'ç ”ç©¶', 'è«–æ–‡', 'å­¦ä¼š', 'å°‚é–€'],
                'description': 'é«˜ç­‰æ•™è‚²é–¢é€£',
                'priority': 1
            },
            'education_methods': {
                'keywords': ['å‹‰å¼·æ³•', 'å­¦ç¿’', 'è¨˜æ†¶', 'é›†ä¸­', 'åŠ¹ç‡', 'æ–¹æ³•'],
                'description': 'å­¦ç¿’æ–¹æ³•ãƒ»æŠ€è¡“',
                'priority': 1
            },
            
            # å“²å­¦ãƒ»æ€æƒ³é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'philosophy_western': {
                'keywords': ['å“²å­¦', 'ãƒ—ãƒ©ãƒˆãƒ³', 'ã‚¢ãƒªã‚¹ãƒˆãƒ†ãƒ¬ã‚¹', 'ã‚«ãƒ³ãƒˆ', 'ãƒ‹ãƒ¼ãƒã‚§'],
                'description': 'è¥¿æ´‹å“²å­¦é–¢é€£',
                'priority': 1
            },
            'philosophy_eastern': {
                'keywords': ['æ±æ´‹å“²å­¦', 'ä»æ•™', 'ç¦…', 'å„’æ•™', 'è€å­', 'å­”å­'],
                'description': 'æ±æ´‹å“²å­¦é–¢é€£',
                'priority': 1
            },
            'philosophy_ethics': {
                'keywords': ['å€«ç†', 'é“å¾³', 'å–„æ‚ª', 'æ­£ç¾©', 'äººæ¨©', 'ä¾¡å€¤è¦³'],
                'description': 'å€«ç†ãƒ»é“å¾³é–¢é€£',
                'priority': 1
            },
            
            # ç¤¾ä¼šãƒ»æ”¿æ²»é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'society_politics': {
                'keywords': ['æ”¿æ²»', 'æ”¿åºœ', 'é¸æŒ™', 'æ°‘ä¸»ä¸»ç¾©', 'æ”¿ç­–', 'å›½ä¼š'],
                'description': 'æ”¿æ²»é–¢é€£',
                'priority': 1
            },
            'society_law': {
                'keywords': ['æ³•å¾‹', 'æ³•', 'è£åˆ¤', 'å¼è­·å£«', 'åˆ¤æ±º', 'æ¨©åˆ©'],
                'description': 'æ³•å¾‹é–¢é€£',
                'priority': 1
            },
            'society_issues': {
                'keywords': ['ç¤¾ä¼šå•é¡Œ', 'ç’°å¢ƒ', 'æ ¼å·®', 'å·®åˆ¥', 'ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼', 'äººæ¨©'],
                'description': 'ç¤¾ä¼šå•é¡Œé–¢é€£',
                'priority': 1
            },
            
            # ç’°å¢ƒãƒ»è‡ªç„¶é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'environment_ecology': {
                'keywords': ['ç’°å¢ƒ', 'ç”Ÿæ…‹ç³»', 'è‡ªç„¶', 'å‹•ç‰©', 'æ¤ç‰©', 'æ£®æ—', 'æµ·æ´‹'],
                'description': 'ç’°å¢ƒãƒ»ç”Ÿæ…‹ç³»é–¢é€£',
                'priority': 1
            },
            'environment_climate': {
                'keywords': ['æ°—å€™', 'å¤©æ°—', 'æ°—è±¡', 'æ¸©æš–åŒ–', 'æ°—å€™å¤‰å‹•', 'ç½å®³'],
                'description': 'æ°—å€™ãƒ»æ°—è±¡é–¢é€£',
                'priority': 1
            },
            
            # å¿ƒç†ãƒ»æ„Ÿæƒ…é–¢é€£ï¼ˆç´°åˆ†åŒ–ï¼‰
            'psychology_cognitive': {
                'keywords': ['å¿ƒç†å­¦', 'èªçŸ¥', 'è¨˜æ†¶', 'å­¦ç¿’', 'çŸ¥è¦š', 'æ€è€ƒ'],
                'description': 'èªçŸ¥å¿ƒç†å­¦é–¢é€£',
                'priority': 1
            },
            'psychology_emotional': {
                'keywords': ['æ„Ÿæƒ…', 'æ°—æŒã¡', 'ã‚¹ãƒˆãƒ¬ã‚¹', 'ç™’ã—', 'å¹¸ã›', 'æ‚²ã—ã¿'],
                'description': 'æ„Ÿæƒ…ãƒ»ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹',
                'priority': 1
            },
            'psychology_social': {
                'keywords': ['ç¤¾ä¼šå¿ƒç†å­¦', 'äººé–“é–¢ä¿‚', 'ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³', 'é›†å›£'],
                'description': 'ç¤¾ä¼šå¿ƒç†å­¦é–¢é€£',
                'priority': 1
            },
            
            # Wisbeeã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é–¢é€£
            'wisbee_character': {
                'keywords': ['wisbee', 'ã‚¦ã‚£ã‚ºãƒ“ãƒ¼', 'ã¿ã¤ã°ã¡', 'ã¶ã‚“ã¶ã‚“', 'ã¯ã¡ã¿ã¤'],
                'description': 'Wisbeeã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é–¢é€£',
                'priority': 0  # æœ€é«˜å„ªå…ˆåº¦
            },
            
            # ãã®ä»–ãƒ»ä¸€èˆ¬
            'general_conversation': {
                'keywords': ['ã“ã‚“ã«ã¡ã¯', 'ã‚ã‚ŠãŒã¨ã†', 'ãŠç–²ã‚Œæ§˜', 'æŒ¨æ‹¶', 'æ—¥å¸¸'],
                'description': 'ä¸€èˆ¬çš„ãªä¼šè©±',
                'priority': 3
            },
            'general_other': {
                'keywords': [],  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã—ï¼ˆãã®ä»–ã™ã¹ã¦ï¼‰
                'description': 'ãã®ä»–ãƒ»æœªåˆ†é¡',
                'priority': 4  # æœ€ä½å„ªå…ˆåº¦
            }
        }
    
    def classify_sample(self, sample: Dict[str, Any]) -> str:
        """ã‚µãƒ³ãƒ—ãƒ«ã‚’è©³ç´°ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
        text = self._extract_text_from_sample(sample)
        text_lower = text.lower()
        
        # å„ã‚«ãƒ†ã‚´ãƒªã¨ã®ãƒãƒƒãƒãƒ³ã‚°åº¦ã‚’è¨ˆç®—
        category_scores = {}
        
        for category, definition in self.category_definitions.items():
            score = 0
            keywords = definition['keywords']
            priority = definition['priority']
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1
            
            # å„ªå…ˆåº¦ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘ï¼ˆå„ªå…ˆåº¦ãŒä½ã„ã»ã©é‡è¦ï¼‰
            if score > 0:
                weight = 5 - priority  # priority 0->5, 1->4, 2->3, 3->2, 4->1
                category_scores[category] = score * weight
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ
        if category_scores:
            best_category = max(category_scores.items(), key=lambda x: x[1])[0]
            return best_category
        
        # ãƒãƒƒãƒã™ã‚‹ã‚«ãƒ†ã‚´ãƒªãŒãªã„å ´åˆã¯general_other
        return 'general_other'
    
    def _extract_text_from_sample(self, sample: Dict[str, Any]) -> str:
        """ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        text = ""
        
        if 'conversations' in sample:
            for conv in sample['conversations']:
                text += conv.get('value', '') + " "
        elif 'instruction' in sample and 'output' in sample:
            text += sample['instruction'] + " " + sample['output']
        elif 'messages' in sample:
            for msg in sample['messages']:
                text += msg.get('content', '') + " "
        elif 'text' in sample:
            text += sample['text']
        
        return text

def load_jsonl_file(file_path: str) -> List[Dict[str, Any]]:
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    if not os.path.exists(file_path):
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return []
    
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if line:
                    try:
                        item = json.loads(line)
                        data.append(item)
                    except json.JSONDecodeError as e:
                        print(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ {file_path}:{line_num}: {e}")
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
    
    return data

def save_categorized_data(categorized_data: Dict[str, List], output_dir: str, samples_per_file: int = 100):
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    os.makedirs(output_dir, exist_ok=True)
    
    saved_files = {}
    
    for category, samples in categorized_data.items():
        if not samples:
            continue
            
        category_dir = os.path.join(output_dir, category)
        os.makedirs(category_dir, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²
        file_count = 0
        for i in range(0, len(samples), samples_per_file):
            file_count += 1
            chunk = samples[i:i + samples_per_file]
            filename = f"{category}_{file_count:03d}.jsonl"
            filepath = os.path.join(category_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                for sample in chunk:
                    f.write(json.dumps(sample, ensure_ascii=False) + '\n')
            
            print(f"ä¿å­˜: {filepath} ({len(chunk)}ã‚µãƒ³ãƒ—ãƒ«)")
        
        saved_files[category] = {
            'total_samples': len(samples),
            'total_files': file_count,
            'samples_per_file': samples_per_file
        }
    
    return saved_files

def create_category_summary(classifier: DetailedCategoryClassifier, categorized_data: Dict[str, List], output_dir: str):
    """ã‚«ãƒ†ã‚´ãƒªã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
    summary = {
        'total_categories': len(categorized_data),
        'total_samples': sum(len(samples) for samples in categorized_data.values()),
        'categories': {}
    }
    
    for category, samples in categorized_data.items():
        definition = classifier.category_definitions.get(category, {})
        summary['categories'][category] = {
            'sample_count': len(samples),
            'description': definition.get('description', ''),
            'keywords': definition.get('keywords', []),
            'priority': definition.get('priority', 99)
        }
    
    # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    summary_file = os.path.join(output_dir, 'category_summary.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    return summary

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ Wisbeeè©³ç´°ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    
    # åˆ†é¡å™¨ã‚’åˆæœŸåŒ–
    classifier = DetailedCategoryClassifier()
    print(f"ğŸ“‚ å®šç¾©æ¸ˆã¿ã‚«ãƒ†ã‚´ãƒªæ•°: {len(classifier.category_definitions)}")
    
    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    input_files = [
        'wisbee_final_training_data.jsonl',
        'wisbee_complete_training_data.jsonl',
        'wisbee_training_data.jsonl',
        'wisbee_extended_training_data.jsonl',
        'balanced_wisbee_training_data.jsonl',
        'wisbee_hamada_training_data.jsonl',
        'wisbee_model_nft_training_data.jsonl'
    ]
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    all_data = []
    for file_path in input_files:
        if os.path.exists(file_path):
            print(f"ğŸ“ èª­ã¿è¾¼ã¿ä¸­: {file_path}")
            data = load_jsonl_file(file_path)
            all_data.extend(data)
            print(f"   {len(data)}ã‚µãƒ³ãƒ—ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
    
    print(f"\nğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(all_data)}ã‚µãƒ³ãƒ—ãƒ«")
    
    # é‡è¤‡é™¤å»
    print("ğŸ”„ é‡è¤‡é™¤å»ä¸­...")
    seen_hashes = set()
    unique_data = []
    
    for item in all_data:
        content = json.dumps(item, sort_keys=True, ensure_ascii=False)
        content_hash = hashlib.md5(content.encode()).hexdigest()
        
        if content_hash not in seen_hashes:
            seen_hashes.add(content_hash)
            unique_data.append(item)
    
    print(f"   é‡è¤‡é™¤å»å¾Œ: {len(unique_data)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   é™¤å»ã•ã‚ŒãŸé‡è¤‡: {len(all_data) - len(unique_data)}ã‚µãƒ³ãƒ—ãƒ«")
    
    # è©³ç´°ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
    print("\nğŸ” è©³ç´°ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ä¸­...")
    categorized_data = defaultdict(list)
    
    for i, sample in enumerate(unique_data):
        if i % 500 == 0:
            print(f"   é€²æ—: {i}/{len(unique_data)} ({i/len(unique_data)*100:.1f}%)")
        
        category = classifier.classify_sample(sample)
        categorized_data[category].append(sample)
    
    print("   åˆ†é¡å®Œäº†")
    
    # åˆ†é¡çµæœã®è¡¨ç¤º
    print("\nğŸ“ˆ è©³ç´°åˆ†é¡çµæœ:")
    sorted_categories = sorted(categorized_data.items(), key=lambda x: len(x[1]), reverse=True)
    
    for category, samples in sorted_categories:
        definition = classifier.category_definitions.get(category, {})
        description = definition.get('description', '')
        print(f"   {category}: {len(samples)}ã‚µãƒ³ãƒ—ãƒ« ({description})")
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_dir = "detailed_categorized_wisbee_data"
    print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ä¿å­˜ä¸­ï¼ˆ{output_dir}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰...")
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    saved_files = save_categorized_data(categorized_data, output_dir, samples_per_file=100)
    
    # ã‚µãƒãƒªãƒ¼ä½œæˆ
    summary = create_category_summary(classifier, categorized_data, output_dir)
    
    print(f"\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªã‚µãƒãƒªãƒ¼ä¿å­˜: {output_dir}/category_summary.json")
    print("\nâœ… è©³ç´°ã‚«ãƒ†ã‚´ãƒªåˆ†é¡å®Œäº†ï¼")
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("ğŸ“‹ è©³ç´°åˆ†é¡ã‚µãƒãƒªãƒ¼")
    print("="*60)
    print(f"ç·ã‚«ãƒ†ã‚´ãƒªæ•°: {len(categorized_data)}")
    print(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(unique_data):,}")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    print("\nä¸Šä½10ã‚«ãƒ†ã‚´ãƒª:")
    
    for i, (category, samples) in enumerate(sorted_categories[:10]):
        definition = classifier.category_definitions.get(category, {})
        description = definition.get('description', '')
        print(f"  {i+1:2d}. {category}: {len(samples):,}ã‚µãƒ³ãƒ—ãƒ« ({description})")

if __name__ == "__main__":
    main()